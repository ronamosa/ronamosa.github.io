"use strict";(self.webpackChunkronamosa_github_io=self.webpackChunkronamosa_github_io||[]).push([[7803],{85884:e=>{e.exports=JSON.parse('{"tag":{"label":"sagemaker","permalink":"/docs/tags/sagemaker","allTagsPath":"/docs/tags","count":2,"items":[{"id":"engineer/AI/DeployLLMToSageMaker","title":"Deploy Large Language Models to AWS SageMaker - Complete Manual Guide","description":"Step-by-step tutorial for manually deploying LLMs to AWS SageMaker endpoints. Learn model preparation, inference code setup, and endpoint deployment for production AI.","permalink":"/docs/engineer/AI/deploy-llm-sagemaker-manual-guide"},{"id":"engineer/AI/Mistral-7B-SageMaker","title":"Deploy Mistral-7B LLM with Ollama on AWS SageMaker","description":"Complete tutorial for deploying and running Mistral-7B large language model using Ollama on AWS SageMaker. Includes setup, configuration, and usage examples.","permalink":"/docs/engineer/AI/Mistral-7B-SageMaker"}],"unlisted":false}}')}}]);