"use strict";(self.webpackChunkronamosa_github_io=self.webpackChunkronamosa_github_io||[]).push([[4108],{28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>a});var i=n(96540);const o={},s=i.createContext(o);function r(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(s.Provider,{value:t},e.children)}},43652:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"engineer/AI/PromptEngChatGPT","title":"ChatGPT Prompt Engineering for Developers - Complete AI Interaction Guide","description":"Comprehensive guide to prompt engineering for developers using ChatGPT. Learn advanced prompting techniques, best practices, and practical examples for software development.","source":"@site/docs/engineer/AI/PromptEngChatGPT.md","sourceDirName":"engineer/AI","slug":"/engineer/AI/PromptEngChatGPT","permalink":"/docs/engineer/AI/PromptEngChatGPT","draft":false,"unlisted":false,"editUrl":"https://github.com/ronamosa/ronamosa.github.io/edit/main/website/docs/engineer/AI/PromptEngChatGPT.md","tags":[{"inline":true,"label":"ai","permalink":"/docs/tags/ai"},{"inline":true,"label":"prompt-engineering","permalink":"/docs/tags/prompt-engineering"},{"inline":true,"label":"chatgpt","permalink":"/docs/tags/chatgpt"},{"inline":true,"label":"development","permalink":"/docs/tags/development"},{"inline":true,"label":"llm","permalink":"/docs/tags/llm"}],"version":"current","lastUpdatedBy":"Ron Amosa","lastUpdatedAt":1758526302000,"sidebarPosition":7,"frontMatter":{"title":"ChatGPT Prompt Engineering for Developers - Complete AI Interaction Guide","description":"Comprehensive guide to prompt engineering for developers using ChatGPT. Learn advanced prompting techniques, best practices, and practical examples for software development.","keywords":["prompt engineering","chatgpt developers","ai prompting","gpt prompts","ai development","llm interaction","chatgpt best practices"],"tags":["ai","prompt-engineering","chatgpt","development","llm"],"sidebar_position":7},"sidebar":"docsSidebar","previous":{"title":"AWS GPT Documentation Assistant - AI-Powered AWS Learning Tool","permalink":"/docs/engineer/AI/AWSGPT"},"next":{"title":"Retrieval Augmented Generation (RAG) - Production-Ready AI Applications Guide","permalink":"/docs/engineer/AI/RetrievalAugmentedGeneration"}}');var o=n(74848),s=n(28453);const r={title:"ChatGPT Prompt Engineering for Developers - Complete AI Interaction Guide",description:"Comprehensive guide to prompt engineering for developers using ChatGPT. Learn advanced prompting techniques, best practices, and practical examples for software development.",keywords:["prompt engineering","chatgpt developers","ai prompting","gpt prompts","ai development","llm interaction","chatgpt best practices"],tags:["ai","prompt-engineering","chatgpt","development","llm"],sidebar_position:7},a=void 0,l={},c=[{value:"Guidelines",id:"guidelines",level:2},{value:"Helper Function",id:"helper-function",level:3},{value:"P1. Write Clear Instructions",id:"p1-write-clear-instructions",level:3},{value:"Tactic 1 - Use delimiters to clearly mark input",id:"tactic-1---use-delimiters-to-clearly-mark-input",level:4},{value:"Tactic 2 - instruct it to provide structure output",id:"tactic-2---instruct-it-to-provide-structure-output",level:4},{value:"Tactic 3 - ask the model to check if conditions were satisfied",id:"tactic-3---ask-the-model-to-check-if-conditions-were-satisfied",level:4},{value:"Tactic 4 - &quot;few shot&quot; prompting",id:"tactic-4---few-shot-prompting",level:4},{value:"P2. Give the Model time to &quot;think&quot;",id:"p2-give-the-model-time-to-think",level:3},{value:"Tactic 1 - specify steps required to complete the task",id:"tactic-1---specify-steps-required-to-complete-the-task",level:4},{value:"Tactic 2 - instruct model to work out its own solution, dont rush a conclusion",id:"tactic-2---instruct-model-to-work-out-its-own-solution-dont-rush-a-conclusion",level:4},{value:"Model Limitations: Hallucinations",id:"model-limitations-hallucinations",level:3}];function p(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.admonition,{type:"info",children:(0,o.jsxs)(t.p,{children:["Link to ",(0,o.jsx)(t.a,{href:"https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/2/guidelines",children:"Guidelines"})," Section."]})}),"\n",(0,o.jsx)(t.p,{children:"I can't remember how I found this, but I thought I'd go through this and learn a few things. Course uses an embedded Jupyter notebook to run python code and provides the OpenAI API key to be used."}),"\n",(0,o.jsx)(t.h2,{id:"guidelines",children:"Guidelines"}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsx)(t.li,{children:"Principle 1: write clear and specific instructions"}),"\n",(0,o.jsx)(t.li,{children:'Principle 2: give the model time to "think"'}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"helper-function",children:"Helper Function"}),"\n",(0,o.jsx)(t.p,{children:"This is your helper function to call OpenAI API"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv(\'OPENAI_API_KEY\')\n\ndef get_completion(prompt, model="gpt-3.5-turbo"):\n    messages = [{"role": "user", "content": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model\'s output\n    )\n    return response.choices[0].message["content"]\n'})}),"\n",(0,o.jsx)(t.h3,{id:"p1-write-clear-instructions",children:"P1. Write Clear Instructions"}),"\n",(0,o.jsx)(t.h4,{id:"tactic-1---use-delimiters-to-clearly-mark-input",children:"Tactic 1 - Use delimiters to clearly mark input"}),"\n",(0,o.jsxs)(t.p,{children:["Delimiters can be anything, backticks, tags, ",(0,o.jsx)(t.code,{children:"<>"})," etc e.g. 3x backticks"]}),"\n",(0,o.jsx)(t.p,{children:"e.g."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'text = f"""\nThis can be anything\\\nYou want it to be\\\n"""\nprompt = f"""\nSummarize the text delimited by triple backticks \\\ninto a single sentence.\n```{text}```\n"""\nresponse = get_completion(prompt)\nprint(response)\n'})}),"\n",(0,o.jsx)(t.h4,{id:"tactic-2---instruct-it-to-provide-structure-output",children:"Tactic 2 - instruct it to provide structure output"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'prompt = f"""\nGenerate a list of three made-up book titles along \\\nwith their authors and genres.\nProvide them in JSON format with the following keys:\nbook_id, title, author, genre.\n"""\nresponse = get_completion(prompt)\nprint(response)\n'})}),"\n",(0,o.jsxs)(t.p,{children:["output instructions = ",(0,o.jsx)(t.code,{children:"Provide them in JSON format with the following keys: book_id, title, author, genre."})]}),"\n",(0,o.jsx)(t.p,{children:"here's another example where you instruct it on how you want it to structure the output"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'\n# Everything under \'Use the following format:\'\n\nprompt_2 = f"""\nYour task is to perform the following actions:\n1 - Summarize the following text delimited by\n  <> with 1 sentence.\n2 - Translate the summary into French.\n3 - List each name in the French summary.\n4 - Output a json object that contains the\n  following keys: french_summary, num_names.\n\nUse the following format:\nText: <text to summarize />\nSummary: <summary />\nTranslation: <summary translation />\nNames: <list of names in Italian summary />\nOutput JSON: <json with summary and num_names />\n\nText: <{text}>\n"""\nresponse = get_completion(prompt_2)\nprint("\\nCompletion for prompt 2:")\nprint(response)\n'})}),"\n",(0,o.jsx)(t.h4,{id:"tactic-3---ask-the-model-to-check-if-conditions-were-satisfied",children:"Tactic 3 - ask the model to check if conditions were satisfied"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'text_1 = f"""\nMaking a cup of tea is easy! First, you need to get some \\\nwater boiling. While that\'s happening, \\\ngrab a cup and put a tea bag in it. Once the water is \\\nhot enough, just pour it over the tea bag. \\\nLet it sit for a bit so the tea can steep. After a \\\nfew minutes, take out the tea bag. If you \\\nlike, you can add some sugar or milk to taste. \\\nAnd that\'s it! You\'ve got yourself a delicious \\\ncup of tea to enjoy.\n"""\n\n# You have this block of text above ^^^\n\n# In your prompt you tell the model where to find the delimited input = triple quotes.\n# You give it instructions for output = If...Step 1...\n# You tell it the "else" = then simply write...\n\nprompt = f"""\nYou will be provided with text delimited by triple quotes.\nIf it contains a sequence of instructions, \\\nre-write those instructions in the following format:\n\nStep 1 - ...\nStep 2 - \u2026\n\u2026\nStep N - \u2026\n\nIf the text does not contain a sequence of instructions, \\\nthen simply write \\"No steps provided.\\"\n\n\\"\\"\\"{text_1}\\"\\"\\"\n"""\nresponse = get_completion(prompt)\nprint("Completion for Text 1:")\nprint(response)\n'})}),"\n",(0,o.jsx)(t.h4,{id:"tactic-4---few-shot-prompting",children:'Tactic 4 - "few shot" prompting'}),"\n",(0,o.jsx)(t.p,{children:'This is where you "model" the types (style?) of answers you want the LLM to give you. In the below, in conversation style, you provide ONE example, child, then grandparent, then child again... and the LLM will "complete the pattern" you have exemplified:'}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'prompt = f"""\nYour task is to answer in a consistent style.\n\n<child />: Teach me about patience.\n\n<grandparent />: The river that carves the deepest \\\nvalley flows from a modest spring; the \\\ngrandest symphony originates from a single note; \\\nthe most intricate tapestry begins with a solitary thread.\n\n<child />: Teach me about resilience.\n"""\nresponse = get_completion(prompt)\nprint(response)\n'})}),"\n",(0,o.jsx)(t.h3,{id:"p2-give-the-model-time-to-think",children:'P2. Give the Model time to "think"'}),"\n",(0,o.jsx)(t.h4,{id:"tactic-1---specify-steps-required-to-complete-the-task",children:"Tactic 1 - specify steps required to complete the task"}),"\n",(0,o.jsxs)(t.p,{children:["Give a block of text=",(0,o.jsx)(t.code,{children:"text"})]}),"\n",(0,o.jsx)(t.p,{children:"Prompt provides the step by step instructions to be done"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'text=f"""\nWhatever....\n"""\n\n# example 1\nprompt_1 = f"""\nPerform the following actions:\n1 - Summarize the following text delimited by triple \\\nbackticks with 1 sentence.\n2 - Translate the summary into French.\n3 - List each name in the French summary.\n4 - Output a json object that contains the following \\\nkeys: french_summary, num_names.\n\nSeparate your answers with line breaks.\n\nText:\n```{text}```\n"""\nresponse = get_completion(prompt_1)\nprint("Completion for prompt 1:")\nprint(response)\n'})}),"\n",(0,o.jsxs)(t.p,{children:["Then you can also ask for specific output format i.e. JSON or the ",(0,o.jsx)(t.a,{href:"#tactic-2---instruct-it-to-provide-structure-output",children:"output tactic above"}),"."]}),"\n",(0,o.jsx)(t.h4,{id:"tactic-2---instruct-model-to-work-out-its-own-solution-dont-rush-a-conclusion",children:"Tactic 2 - instruct model to work out its own solution, dont rush a conclusion"}),"\n",(0,o.jsx)(t.p,{children:"This is a much bigger prompt, where we have a) instructions b) output structure we want and c) the question"}),"\n",(0,o.jsx)(t.p,{children:"Dont just prompt to say:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'prompt = f"""\nDetermine if the student\'s solution is correct or not.\n\nQuestion:...\n...\n"""\n'})}),"\n",(0,o.jsx)(t.p,{children:"Instead, be very explicit:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"prompt = f\"\"\"\nYour task is to determine if the student's solution \\\nis correct or not.\nTo solve the problem do the following:\n- First, work out your own solution to the problem.\n- Then compare your solution to the student's solution \\\nand evaluate if the student's solution is correct or not.\nDon't decide if the student's solution is correct until\nyou have done the problem yourself.\n"})}),"\n",(0,o.jsx)(t.p,{children:"follow that with the output you want e.g."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'"""\nQuestion:\n```question here```\n\nAnswer:\n```corrent or incorrect```\n\n"""\n'})}),"\n",(0,o.jsxs)(t.p,{children:["And because ",(0,o.jsx)(t.code,{children:"question here"})," is between the delimters, the actual question from the ",(0,o.jsx)(t.code,{children:"text=some text e.g. the question"})," gets substituted in. So too, you have the heading ",(0,o.jsx)(t.code,{children:"Answer:"})," and then the model will determine if the students answer is ",(0,o.jsx)(t.code,{children:"correct"})," or ",(0,o.jsx)(t.code,{children:"incorrect"}),"."]}),"\n",(0,o.jsx)(t.h3,{id:"model-limitations-hallucinations",children:"Model Limitations: Hallucinations"}),"\n",(0,o.jsxs)(t.p,{children:['Reduce hallucinations by using these tactics in this guidelines section, but also to ask the model to "first find relevant information, and then answer the qeustion based on the relevant information" - have a way to trace the answer back to a ',(0,o.jsx)(t.em,{children:"source document"})," will help it move away from hallucinations."]})]})}function d(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}}}]);