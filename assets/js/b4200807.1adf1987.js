"use strict";(self.webpackChunkronamosa_github_io=self.webpackChunkronamosa_github_io||[]).push([[93964],{28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var t=i(96540);const r={},s=t.createContext(r);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:n},e.children)}},42215:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"engineer/AI/AgenticRagLlamaIndex","title":"Building Agentic RAG with LlamaIndex - Advanced AI Agent Development","description":"Complete guide to building agentic RAG systems with LlamaIndex. Learn advanced AI agent development, retrieval-augmented generation, and intelligent document processing.","source":"@site/docs/engineer/AI/AgenticRagLlamaIndex.md","sourceDirName":"engineer/AI","slug":"/engineer/AI/AgenticRagLlamaIndex","permalink":"/docs/engineer/AI/AgenticRagLlamaIndex","draft":false,"unlisted":false,"editUrl":"https://github.com/ronamosa/ronamosa.github.io/edit/main/website/docs/engineer/AI/AgenticRagLlamaIndex.md","tags":[{"inline":true,"label":"ai","permalink":"/docs/tags/ai"},{"inline":true,"label":"rag","permalink":"/docs/tags/rag"},{"inline":true,"label":"llamaindex","permalink":"/docs/tags/llamaindex"},{"inline":true,"label":"agents","permalink":"/docs/tags/agents"},{"inline":true,"label":"llm","permalink":"/docs/tags/llm"}],"version":"current","lastUpdatedBy":"Ron Amosa","lastUpdatedAt":1771617957000,"sidebarPosition":3,"frontMatter":{"title":"Building Agentic RAG with LlamaIndex - Advanced AI Agent Development","description":"Complete guide to building agentic RAG systems with LlamaIndex. Learn advanced AI agent development, retrieval-augmented generation, and intelligent document processing.","keywords":["agentic rag","llamaindex","ai agents","rag system","retrieval augmented generation","llm agents","intelligent agents","ai development"],"tags":["ai","rag","llamaindex","agents","llm"],"sidebar_position":3},"sidebar":"docsSidebar","previous":{"title":"PrivateGPT on AWS EC2 - Secure Cloud-Based Document Chat with LLMs","permalink":"/docs/engineer/AI/PrivateGPTAWS"},"next":{"title":"Deploy Large Language Models to AWS SageMaker - Complete Manual Guide","permalink":"/docs/engineer/AI/deploy-llm-sagemaker-manual-guide"}}');var r=i(74848),s=i(28453);const o={title:"Building Agentic RAG with LlamaIndex - Advanced AI Agent Development",description:"Complete guide to building agentic RAG systems with LlamaIndex. Learn advanced AI agent development, retrieval-augmented generation, and intelligent document processing.",keywords:["agentic rag","llamaindex","ai agents","rag system","retrieval augmented generation","llm agents","intelligent agents","ai development"],tags:["ai","rag","llamaindex","agents","llm"],sidebar_position:3},a=void 0,l={},d=[{value:"Router Query Engine",id:"router-query-engine",level:2},{value:"Query Engines",id:"query-engines",level:2},{value:"Router Query Engine Request",id:"router-query-engine-request",level:2},{value:"get_router_query_engine(&quot;metagpt.pdf&quot;)",id:"get_router_query_enginemetagptpdf",level:3}];function c(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsxs)(n.p,{children:["Link to ",(0,r.jsx)(n.a,{href:"https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/1/introduction",children:"DeepLearning.AI"})," Section."]})}),"\n",(0,r.jsx)(n.h2,{id:"router-query-engine",children:"Router Query Engine"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"import libs"}),"\n",(0,r.jsx)(n.li,{children:"setup API key"}),"\n",(0,r.jsx)(n.li,{children:"load, split and get nodes from document"}),"\n",(0,r.jsx)(n.li,{children:"setup LLM and embedding"}),"\n",(0,r.jsx)(n.li,{children:"create indexes, summary, vector"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import os\nimport nest_asyncio\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.core import Settings\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.core import SummaryIndex, VectorStoreIndex\nfrom llama_index.core.tools import QueryEngineTool\nfrom llama_index.core.query_engine.router_query_engine import RouterQueryEngine\nfrom llama_index.core.selectors import LLMSingleSelector\nfrom .utils import get_router_query_engine\n\ndef get_openai_api_key():\n    openai_api_key = os.getenv("OPENAI_API_KEY")\n    return openai_api_key\n\nOPENAI_API_KEY = get_openai_api_key()\n\nnest_asyncio.apply()\n\n# load documents\ndocuments = SimpleDirectoryReader(input_files=["metagpt.pdf"]).load_data()\n\n# split documents into nodes\nsplitter = SentenceSplitter(chunk_size=1024)\nnodes = splitter.get_nodes_from_documents(documents)\n\n# set up LLM and embeddings\nSettings.llm = OpenAI(model="gpt-3.5-turbo")\nSettings.embed_model = OpenAIEmbedding(model="text-embedding-ada-002")\n\n# create indexes\nsummary_index = SummaryIndex(nodes)\nvector_index = VectorStoreIndex(nodes)\n'})}),"\n",(0,r.jsxs)(n.admonition,{type:"note",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Summary Index"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Think of it like a book's chapter summaries"}),"\n",(0,r.jsx)(n.li,{children:"It creates hierarchical summaries of your documents"}),"\n",(0,r.jsx)(n.li,{children:"Good for questions that need broad understanding or synthesis of the content"}),"\n",(0,r.jsx)(n.li,{children:'Better for "What\'s the main point of...?" or "Summarize..." type questions'}),"\n",(0,r.jsx)(n.li,{children:"Uses LLM to generate summaries, which can be more expensive but gives better high-level understanding"}),"\n"]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Vector Index"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Think of it like a smart Ctrl+F search"}),"\n",(0,r.jsx)(n.li,{children:"Converts text chunks into numerical vectors (like GPS coordinates for meaning)"}),"\n",(0,r.jsx)(n.li,{children:"Good for finding specific information or answering detailed questions"}),"\n",(0,r.jsx)(n.li,{children:'Better for "Where does it mention...?" or "What are the specific details about...?" type questions'}),"\n",(0,r.jsx)(n.li,{children:"Uses similarity search to find relevant chunks, which is faster and cheaper than summarization"}),"\n"]}),(0,r.jsx)(n.p,{children:"In your code, you're using both because they complement each other:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Summary index (summary_tool) for summarization questions"}),"\n",(0,r.jsx)(n.li,{children:"Vector index (vector_tool) for specific detail retrieval"}),"\n"]})]}),"\n",(0,r.jsx)(n.h2,{id:"query-engines",children:"Query Engines"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Create 2x Query Engines: ",(0,r.jsx)(n.code,{children:"summary_query_engine"})," and ",(0,r.jsx)(n.code,{children:"vector_query_engine"})]}),"\n",(0,r.jsxs)(n.li,{children:["Create 2x Query Engine Tools: ",(0,r.jsx)(n.code,{children:"summary_tool"})," and ",(0,r.jsx)(n.code,{children:"vector_tool"})]}),"\n",(0,r.jsxs)(n.li,{children:["Create 1x RouterQueryEngine: ",(0,r.jsx)(n.code,{children:"query_engine"})]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'\n# create query engines\nsummary_query_engine = summary_index.as_query_engine(\n    response_mode="tree_summarize",\n    use_async=True,\n)\nvector_query_engine = vector_index.as_query_engine()\n\n# create router query engine\nsummary_tool = QueryEngineTool.from_defaults(\n    query_engine=summary_query_engine,\n    description=(\n        "Useful for summarization questions related to MetaGPT"\n    ),\n)\n\nvector_tool = QueryEngineTool.from_defaults(\n    query_engine=vector_query_engine,\n    description=(\n        "Useful for retrieving specific context from the MetaGPT paper."\n    ),\n)\n\n# create router query engine\nquery_engine = RouterQueryEngine(\n    selector=LLMSingleSelector.from_defaults(),\n    query_engine_tools=[\n        summary_tool,\n        vector_tool,\n    ],\n    verbose=True\n)\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Testing direct calls to each Query Engine with: ",(0,r.jsx)(n.code,{children:"query_engine.query()"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'\n# response\nresponse = query_engine.query("What is the summary of the document?")\nprint(str(response))\n'})}),"\n",(0,r.jsx)(n.p,{children:"This was the response:"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Selecting query engine 0: Useful for summarization questions related to MetaGPT."})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The document introduces MetaGPT, a meta-programming framework that enhances multi-agent systems using Large Language Models (LLMs) by incorporating human-like Standardized Operating Procedures (SOPs). It assigns specific roles to agents, streamlines workflows, and improves task decomposition, ensuring efficient collaboration through structured outputs and a communication protocol. MetaGPT achieves state-of-the-art performance in code generation benchmarks, emphasizing role specialization, workflow management, and efficient sharing mechanisms. The framework also includes an executable feedback mechanism to iteratively improve code quality. Additionally, the document discusses the software development process with MetaGPT, highlighting its success in achieving superior performance and its potential for future research in human-inspired techniques for artificial multi-agent systems."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"\nprint(len(response.source_nodes))\n34\n\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'\nresponse = query_engine.query(\n    "How do agents share information with other agents?"\n)\nprint(str(response))\n'})}),"\n",(0,r.jsx)(n.p,{children:"This was the response:"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Selecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context, which is necessary for understanding how agents share information with other agents.."})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Agents share information with other agents by utilizing a shared message pool where they can publish structured messages. This shared message pool allows all agents to exchange messages directly, enabling them to both publish their own messages and access messages from other entities transparently. Additionally, agents can subscribe to relevant messages based on their role profiles, allowing them to extract the information they need for their specific tasks and responsibilities."}),"\n",(0,r.jsx)(n.h2,{id:"router-query-engine-request",children:"Router Query Engine Request"}),"\n",(0,r.jsx)(n.p,{children:"Now, to call the Router Query Engine itself:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# everything together\n\nquery_engine = get_router_query_engine("metagpt.pdf")\nresponse = query_engine.query("Tell me about the ablation study results?")\nprint(str(response))\n'})}),"\n",(0,r.jsx)(n.p,{children:"Final Router determined response:"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Selecting query engine 1: Ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant.."})}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The ablation study results show that MetaGPT effectively addresses challenges related to context utilization, code hallucinations, and information overload in software development. By accurately unfolding natural language descriptions, maintaining information validity, and focusing on granular tasks like requirement analysis, MetaGPT mitigates issues such as incomplete implementation, missing dependencies, and undiscovered bugs. Additionally, the use of a global message pool and subscription mechanism helps manage information overload by streamlining communication and filtering out irrelevant contexts, thereby enhancing the relevance and utility of information in software development."}),"\n",(0,r.jsx)(n.h3,{id:"get_router_query_enginemetagptpdf",children:'get_router_query_engine("metagpt.pdf")'}),"\n",(0,r.jsxs)(n.p,{children:["This function is in a ",(0,r.jsx)(n.code,{children:"utils.py"})," file in this setup, and bottom of the imports list (see above):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def get_router_query_engine(file_path: str, llm = None, embed_model = None):\n    """Get router query engine."""\n    llm = llm or OpenAI(model="gpt-3.5-turbo")\n    embed_model = embed_model or OpenAIEmbedding(model="text-embedding-ada-002")\n    \n    # load documents\n    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n    \n    splitter = SentenceSplitter(chunk_size=1024)\n    nodes = splitter.get_nodes_from_documents(documents)\n    \n    summary_index = SummaryIndex(nodes)\n    vector_index = VectorStoreIndex(nodes, embed_model=embed_model)\n    \n    summary_query_engine = summary_index.as_query_engine(\n        response_mode="tree_summarize",\n        use_async=True,\n        llm=llm\n    )\n    vector_query_engine = vector_index.as_query_engine(llm=llm)\n    \n    summary_tool = QueryEngineTool.from_defaults(\n        query_engine=summary_query_engine,\n        description=(\n            "Useful for summarization questions related to MetaGPT"\n        ),\n    )\n    \n    vector_tool = QueryEngineTool.from_defaults(\n        query_engine=vector_query_engine,\n        description=(\n            "Useful for retrieving specific context from the MetaGPT paper."\n        ),\n    )\n    \n    query_engine = RouterQueryEngine(\n        selector=LLMSingleSelector.from_defaults(),\n        query_engine_tools=[\n            summary_tool,\n            vector_tool,\n        ],\n        verbose=True\n    )\n    return query_engine\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);