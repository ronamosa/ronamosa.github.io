---
slug: ai-chatgpt-bullshit-generator-class-wars-why-do
title: 'AI & ChatGPT: The Bullshit Generator, Class Wars and Why Do We Even Bother?'
description: Exposes exploitative labor practices behind AI training using underpaid workers in Kenya processing traumatic content for ChatGPT. Essential reading for underst
date: 2023-03-14
authors: [ron]
keywords:
- AI
- ChatGPT
- labor exploitation
- ethics
tags:
- AI-Security-Exploitation
- career
reading_time: 11
word_count: 2107
hide_table_of_contents: false
draft: false
---
Talofa reader,

I went down a rabbit hole of ChatGPT and AI this week. Itâ€™s been a hot topic for a short while now since ChatGPTâ€™s release in November, 2022 and thereâ€™s no shortage of articles about it in myReadwisefeed.

Thereâ€™s been a lot of takes, some pro, some con. My friend DZâ€™snewslettergot me thinking about the darker side of AI and so I thought Iâ€™d read up on it this past week and write some stuff down.

Itâ€™s a bit of a read so if you donâ€™t mind a bit of profanity and bad punctuation, enjoy.

<!-- truncate -->

## What is ChatGPT & AI Reaaaally?

Letâ€™s start with what we know about ChatGPT.

ChatGPT is an AI chatbot developed by OpenAI and built on top of OpenAIâ€™s GPT3 family of â€œLarge Language Modelsâ€ (**LLM**) and fine tuned using supervised and reinforcement learning techniques[1](#footnote-1).

The**GPT**stands for*â€œGenerative Pre-trained Transformerâ€*. The**Generative**part means it generates human-like text. Itâ€™s**Pre-trained**on a massive amount of text data (publicly available data from the internet for example) and uses the â€œ**Transformer**â€ deep learning model that uses mechanisms to pay attention to and weigh the significance of the words in the data itâ€™s processing.

### AI: But How Intelligent?

Maybe itâ€™s just me but it took looking further into what â€œintelligenceâ€ actually means here in the context of AI to understand thatâ€™s itâ€™s notT1000about to suddenly figure out how to chase us down and kill us all with multiple martial arts techniques it has just watched on TV.

AI is trained on a very specific thing, so its deep on that one thing, and pretty useless at anything outside of it e.g. an AI beat a chess grand master but would fail a basic maths test because it has no idea what youâ€™re talking about i.e. it hasnâ€™t been trained on maths.

### So Whatâ€™s AGI?

This is a super oversimplified take on the difference, but I think itâ€™s important to know that there are two different â€œAIâ€ that people talk about, and will sometimes confuse and conflate when talking about the thing thatâ€™s going to take over the world and kill us vs. the one thatâ€™ll beat us at chess.

AGI, thanks to Wikipedia, is:

**Artificial general intelligence** (**AGI**) is the ability of an intelligent agent to understand or learn any intellectual task that human beings or other animals can.

So, AI will only know how to kill us if we train it accordingly. But AGI will figure out how to kill us all on its own.

AGI aside, how are we training these AI models?

## How Are These AI Being Trained?

You could be forgiven for thinking the AI world is a super slick computer enhanced synthesis of automation and maths wizardry efficiency.

Itâ€™s not.

OpenAIâ€™sblogtell us:

We trained an initial model using supervised fine-tuning:**human AI trainers**provided conversations in which they played both sidesâ€”the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses.

Ok, so humans help train these models.. tell me more

To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot.

Cool. More humans, doing the fine-tuning.

You can see humans in Steps 1 & 2 of the OpenAI diagram (Step 3 is what the marketing hype sounds like.. â€œwhat humans?!â€)

So what? People are being employed to provide training to AI models.

Sure, letâ€™s have a look at these workersâ€¦

## Humans of AI Development

Following my nose and reading through the lesser known and talked about (at least on my mainstream social media) articles on the negative aspects involving AI has been educational and unsurprising.

None of this negative shit is new. The powerful exploit the less powerful. Itâ€™s like a law of nature at this point.

In 2017, Mary L. Gray and Siddharth Suri wroteâ€˜The Humans Working Behind the AI Curtainâ€™citing Facebookâ€™s supposedly "unbiased algorithm" that turned out to be powered by regular humans (you know, the kind susceptible to "bias"). Imagine my surprise to find that, in 2022, Chloe Xiang's pieceâ€˜AI Isnâ€™t Artificial or Intelligentâ€™suggests we're pretty much in the same position, powering our AI innovation with underpaid workers in foreign countries, or by the better-known term, the "Global South".

In 2016, it was people like middle-aged mother of two Kala, sitting on a computer in Bangalore, India, looking through NSFW content for the likes of Google, Facebook, and Twitter. In 2022, we've either expanded or just relocated the "crucial contributions" work to Kenya, where we read about it in Time's'Inside Facebook's African Sweatshop'in February, with Vice bringing it home in Jan 2023 with an article detailing how â€˜OpenAI Used Kenyan Workers Making $2 an Hour to Filter Traumatic Content From ChatGPTâ€™.

But this is all OK. You know why? Cos â€œimpact sourcingâ€ /s

### â€œImpact Sourcingâ€

Now Iâ€™ve heard some bullshit in my time when it comes to tech marketing, or corporate social responsibility marketing and branding but learning this term â€œimpact sourcingâ€ in the context of this AI training work has been an absolute stunner.

What is â€œimpact sourcingâ€?

**Impact sourcing**, also known as**socially responsible outsourcing**, refers to an arm of thebusiness process outsourcing(BPO) industry. It employs people at thebase of the pyramidor socioeconomically disadvantaged individuals as principal workers in BPO centers to provide**high-quality**, information-based services to domestic and international clients.

You could only seriously believe you are bettering the lives of these workers if you believe the PTSD from sorting through NSFW text and images every day, for $2 an hour, is an improvement on their lives.

And I guess thatâ€™s the point, we believe these people are beneath us and our AI goals.

Not necessarily that we literally think the thought â€œwe are better than themâ€, but that our actions will amount to â€œthey are not important enough for us to change our behaviour thatâ€™s complicit in this outcomeâ€.

Which brings us toâ€¦

## The Classic â€œUsâ€ vs â€œThemâ€

Itâ€™s just a matter of distinguishing which â€œusâ€ is â€œusâ€ this time. Poor? Non-white? A little from column A, a little from column B? A Union B?

### The Class War.

We all know about the inherent biases in our technology. Weâ€™ve known about it for a while now.

We've long talked about and identified how the lack of representation and input at the "tables" of those who develop and build our tech result in things like cameras that can't pick up black skin, ormedical schoolcomputer program inviting applicants for interviews based on gender and non-European names.

AI brings a whole other dimension to that. Dan McQuillan in his piece'We Come to Bury ChatGPT, Not to Praise It.'[2](#footnote-2)talks about how OpenAI CEO Sam Altman thinks of people as 'stochastic parrots' - meaning people are just large language models with learned patterns of behaviour and nothing more (yes, paraphrasing and simplifying). It's an idea seemingly only applied to us ordinary folk, and the "elites" of our society are apparently something better. So of course, us "ordinary folk" are perfect fodder to feed the AI machine meant to serve the upper class withfree training labourfor Googleâ€™s reCAPTCHA to train their models.

### Digital Colonialism.

I'm introduced to the idea of "Digital Colonialism" in Arvind Narayanan's articleâ€˜Digital inequalities will power digital colonialismâ€™. The idea that people are treated differently based on what country they're from is pretty standard colonialism.

We can do it digitally now.

When India was used as a testing ground for a Bing chatbot and users complained to Microsoft about the chatbots abusive behaviour, nothing was done. But when the issues made it to The New York Times, Microsoft made changes within days. That's digital colonialism.

But the example he uses that really brings this idea home is of Sam Altman, CEO of OpenAI (which makes ChatGPT), talking about how people who can't afford healthcare, can use a really smart chatbot. The fact they see can't see anything wrong with this - that rich people have doctors, poor people have chatbots - is mind-blowing but not surprising.

## Why Am I Calling It a â€˜Bullshit Generatorâ€™?

I got this phrase from Dan McQuillans no-holds-barred pieceâ€˜We come to bury ChatGPT, not to praise it.â€™, which I thought was brilliant.

Dan says:

"ChatGPT is, in technical terms, a '**bullshit generator**'. If a generated sentence makes sense to you, the reader, it means the mathematical model has made sufficiently good guess to pass your sense-making filter.**The language model has no idea what it's talking about because it has no idea about anything at all**. It's more of a bullshitter than the most egregious egoist you'll ever meet, producing baseless assertions withunfailing confidencebecause that's what it's designed to do."

Brilliant because he calls out the uglier realities behind the technology and also the kinds of people and ideas who benefit from such technology and how they count as nothing, "the immediate vulnerability of millions of ordinary people" exploited for AI's gain.

Iâ€™m pretty sure I couldâ€™ve just summed up this whole newsletter with this paragraph. But this is a learning exercise, hence why all the notes ğŸ˜.

## What Can We Do about this?

Unlike AI, Iâ€™m okay with saying â€œI donâ€™t knowâ€ the answer to a question.

Because I donâ€™t.

Arvind Narayanan lists a few positives about ChatGPT inâ€˜ChatGPT is a bullshit generator. But it can still be amazingly usefulâ€™where it can help in context where the truth or accuracy isnâ€™t important (fiction) and debugging code. But then notes a study done that found*â€œCopilot generated insecure code****40%****of the time.â€*.

Awesome ğŸ˜‚.

I think of 'what can we do?' in this context - i.e. of the big AI machine and its impending impacts on the world, as well as its current impact on the humans being fed to its development - the same way I look at individual recycling to clean up the world's pollution and climate issues: pretty useless at the individual level, and would instead need some sort of massive groundswell force of public opinion and civic action to force the powerful to change the situation.

I donâ€™t see that happening.

Abstaining from using these tools wonâ€™t change anything the same way vegans and the plant-based meat industry havenâ€™t change our meat eating habits.

So, in my humble opinion, learn how AI really works, how it will impact you, your job, and your community. Teach what you know -*actually*know, stop just reading headlines and parroting the marketing bullshit hype - and read widely, discuss, and share with your community.

My â€œalwaysâ€ take on new tech and itâ€™s almost guaranteed potential for harm to people is the same as in professional fighting - â€œprotect yourself at all timesâ€.

*Thanks for reading. I'll see you in the next episode.*

Share### Learning

*Things Iâ€™m actively studying or learning this weekâ€¦*

- Studying for theâ€˜AWS Certified Security - Specialityâ€™certificate.

### Building

*Things Iâ€™m building or working on this weekâ€¦*

- reviving a recent side-project on a sentiment-analysis pipeline for YouTube channels:https://github.com/ronamosa/aws-youtube-analyze-arch

- Updating myblogto be searchable and add more docs.

### Interesting Reads

*Articles or other writing that stood out to me this weekâ€¦*

- â€˜AI Search Engines And The Quest For Ignoranceâ€™- by Marcus Hutchins

- â€˜Have I Been Trainedâ€™â€” tool for artists to check if their artwork has been used to train AI models likeStable Diffusionand flag them for removal i.e. opt-out.

### Community

*Other projects in community Iâ€™m working onâ€¦*

- Pasifika Tech Education Charity-*Providing Tech Learning Opportunities for the Pasifika Community.*

- Pasifika Tech Network-*A Network for Pasifika Tech Professionals & Learners.*


